{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLm/bLECBZiHj87CpOGeBT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This demo is used to help you understanding the source code of transformer, we will need to build an original transformer model from scratch and do a simulated training process of transformer on the random sample data created."],"metadata":{"id":"-7ZeCyjBXwPh"}},{"cell_type":"markdown","source":["### Import packages"],"metadata":{"id":"0xZcN4eyXTdB"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import math\n","import copy"],"metadata":{"id":"mnUFK8pPXV8V","executionInfo":{"status":"ok","timestamp":1725005917499,"user_tz":-480,"elapsed":386,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["### Multi-head Attention\n","\n","Hint:\n","1. d_model is the hidden dimension of the model, which will be used for q, k and v\n","2. K, Q and V are implemented with linear layer\n","3. Refer to transformer's attention score formula to calculate attention score"],"metadata":{"id":"6UcvOrwsWr_m"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.d_k = d_model // num_heads\n","\n","        # TODO: Implement K, Q and V\n","        # self.W_q = ..\n","        # self.W_k = ...\n","        # self.W_v = ...\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        # TODO: calculate attention score\n","        # attn_scores = ...\n","        if mask is not None:\n","            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n","        attn_probs = torch.softmax(attn_scores, dim=-1)\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        batch_size, seq_length, d_model = x.size()\n","        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        batch_size, _, seq_length, d_k = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","\n","    def forward(self, Q, K, V, mask=None):\n","        Q = self.split_heads(self.W_q(Q))\n","        K = self.split_heads(self.W_k(K))\n","        V = self.split_heads(self.W_v(V))\n","\n","        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output"],"metadata":{"id":"Pua2AebHWvAx","executionInfo":{"status":"ok","timestamp":1725005762998,"user_tz":-480,"elapsed":396,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### Implement FFN"],"metadata":{"id":"m44mFeKqWxUX"}},{"cell_type":"code","source":["class PositionWiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super(PositionWiseFeedForward, self).__init__()\n","        # TODO: Implement fc layers of FFN\n","        # self.fc1 = ...\n","        # self.fc2 = ...\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))"],"metadata":{"id":"fySor28kW1BR","executionInfo":{"status":"ok","timestamp":1725005785494,"user_tz":-480,"elapsed":380,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### Implement positional embedding\n","\n","Hint:\n","1. Refer to transformer PE formula to implement the PE with sin and cos function\n","2. div_term should be used"],"metadata":{"id":"9gUCvatnW2vQ"}},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_seq_length):\n","        super(PositionalEncoding, self).__init__()\n","\n","        pe = torch.zeros(max_seq_length, d_model)\n","        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","\n","        # TODO: Implement positional encoding\n","        # pe[:, 0::2] = ...\n","        # pe[:, 1::2] = ...\n","\n","        self.register_buffer('pe', pe.unsqueeze(0))\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)]"],"metadata":{"id":"lCHn3xMvW55m","executionInfo":{"status":"ok","timestamp":1725005806511,"user_tz":-480,"elapsed":448,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"ZI1rb6tZW8Bq"}},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(EncoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask):\n","        # TODO\n","        return x"],"metadata":{"id":"Bm5cK0rxW9sI","executionInfo":{"status":"ok","timestamp":1725005820539,"user_tz":-480,"elapsed":383,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"1y49edYvXAFs"}},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(DecoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_output, src_mask, tgt_mask):\n","        # TODO\n","        return x"],"metadata":{"id":"sNLj4oZLW_NA","executionInfo":{"status":"ok","timestamp":1725005839525,"user_tz":-480,"elapsed":356,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["### Combine all the modules"],"metadata":{"id":"Os6gkOePXEsD"}},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n","        super(Transformer, self).__init__()\n","        # TODO: Create transformer model\n","        # self.encoder_embedding = ...\n","        # self.decoder_embedding = ...\n","        # self.positional_encoding = ...\n","\n","        # self.encoder_layers = ...\n","        # self.decoder_layers = ...\n","\n","        # self.fc = ...\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def generate_mask(self, src, tgt):\n","        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n","        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n","        seq_length = tgt.size(1)\n","        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n","        tgt_mask = tgt_mask & nopeak_mask\n","        return src_mask, tgt_mask\n","\n","    def forward(self, src, tgt):\n","        src_mask, tgt_mask = self.generate_mask(src, tgt)\n","        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n","        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n","\n","        enc_output = src_embedded\n","        for enc_layer in self.encoder_layers:\n","            enc_output = enc_layer(enc_output, src_mask)\n","\n","        dec_output = tgt_embedded\n","        for dec_layer in self.decoder_layers:\n","            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n","\n","        output = self.fc(dec_output)\n","        return output"],"metadata":{"id":"NfkwGj3AXHNh","executionInfo":{"status":"ok","timestamp":1725005859962,"user_tz":-480,"elapsed":441,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["### Traing the model\n","\n","Hint:\n","1. The training process of transformer is the normal training loop of deep neural networks"],"metadata":{"id":"nNubj0e5XKYc"}},{"cell_type":"code","source":["src_vocab_size = 5000\n","tgt_vocab_size = 5000\n","d_model = 512\n","num_heads = 8\n","num_layers = 6\n","d_ff = 2048\n","max_seq_length = 100\n","dropout = 0.1\n","\n","transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n","\n","# Generate random sample data\n","src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n","tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)"],"metadata":{"id":"ceUtQqI0XMAK","executionInfo":{"status":"ok","timestamp":1725005884621,"user_tz":-480,"elapsed":1274,"user":{"displayName":"Minghao Shao","userId":"04813299213631708430"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss(ignore_index=0)\n","optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n","\n","transformer.train()\n","\n","for epoch in range(100):\n","    # TODO: Training loop\n","    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"],"metadata":{"id":"MyEWYydDXPZx"},"execution_count":null,"outputs":[]}]}